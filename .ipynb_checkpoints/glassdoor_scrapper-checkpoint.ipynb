{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9882cb4e-c0ac-42d9-9dc2-4b82fbea16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "131d189f-e5f3-4507-827f-387552d1ad1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job scrapper\n",
      "Attempting to fetch new joblisting\n",
      "âœ… Found 30 job cards on page 1.\n",
      "âœ… Scraped 1/20: Front End Software Engineer @ Sparksuite\n",
      "âœ… Scraped 2/20: Senior Backend Software Engineer @ CompScience\n",
      "âœ… Scraped 3/20: Software Engineer (Junior) @ Terran Robotics Inc.\n",
      "âœ… Scraped 4/20: Associate Software Engineer @ Protolabs\n",
      "âœ… Scraped 5/20: Software Engineer II @ Payscale\n",
      "âœ… Scraped 6/20: Full Stack Engineer @ Campfire\n",
      "âœ… Scraped 7/20: Software Engineer, Frontend - SevenRooms @ DoorDash USA\n",
      "âœ… Scraped 8/20: Assoc Engineer, Software @ T-Mobile USA, Inc.\n",
      "âœ… Scraped 9/20: Junior Full Stack Developer @ Vivacity Tech PBC\n",
      "âœ… Scraped 10/20: PHP Software Engineer @ INSHUR\n",
      "âœ… Scraped 11/20: Software Engineer @ Barco\n",
      "âœ… Scraped 12/20: Software Developer (Full Stack) @ Intelerad\n",
      "âœ… Scraped 13/20: Software Engineer - Backend @ Navan\n",
      "âœ… Scraped 14/20: Software Engineer @ FTS Inc\n",
      "âœ… Scraped 15/20: Full Stack Developer @ Minerva Coach\n",
      "âœ… Scraped 16/20: Software Engineer II @ Synapse Health\n",
      "âœ… Scraped 17/20: Senior Software Engineer, Backend @ Included Health\n",
      "âœ… Scraped 18/20: Software Engineer - @ Netsmart Technologies\n",
      "âœ… Scraped 19/20: Software Engineer @ BWI Companies, Inc.\n",
      "âœ… Scraped 20/20: Software Engineer @ Fashion Nova\n",
      "\n",
      "ðŸ“Š Total jobs scraped: 20\n",
      "\n",
      "First few jobs:\n",
      "                                       title                company  \\\n",
      "0                Front End Software Engineer             Sparksuite   \n",
      "1           Senior Backend Software Engineer            CompScience   \n",
      "2                 Software Engineer (Junior)   Terran Robotics Inc.   \n",
      "3                Associate Software Engineer              Protolabs   \n",
      "4                       Software Engineer II               Payscale   \n",
      "5                        Full Stack Engineer               Campfire   \n",
      "6   Software Engineer, Frontend - SevenRooms           DoorDash USA   \n",
      "7                   Assoc Engineer, Software     T-Mobile USA, Inc.   \n",
      "8                Junior Full Stack Developer      Vivacity Tech PBC   \n",
      "9                      PHP Software Engineer                 INSHUR   \n",
      "10                         Software Engineer                  Barco   \n",
      "11           Software Developer (Full Stack)              Intelerad   \n",
      "12               Software Engineer - Backend                  Navan   \n",
      "13                         Software Engineer                FTS Inc   \n",
      "14                      Full Stack Developer          Minerva Coach   \n",
      "15                      Software Engineer II         Synapse Health   \n",
      "16         Senior Software Engineer, Backend        Included Health   \n",
      "17                       Software Engineer -  Netsmart Technologies   \n",
      "18                         Software Engineer    BWI Companies, Inc.   \n",
      "19                         Software Engineer           Fashion Nova   \n",
      "\n",
      "                location                             salary rating Posted  \\\n",
      "0             Spring, TX    $88K - $96K (Employer provided)      0          \n",
      "1      San Francisco, CA  $150K - $175K (Employer provided)    3.6          \n",
      "2                 Remote   $70K - $110K (Employer provided)      0          \n",
      "3         North Carolina    $73K - $97K (Employer provided)    2.7          \n",
      "4            Seattle, WA   $94K - $142K (Employer provided)    3.1          \n",
      "5      San Francisco, CA     $122K - $200K (Glassdoor est.)    3.7          \n",
      "6           New York, NY  $131K - $192K (Employer provided)    3.6          \n",
      "7             Frisco, TX   $67K - $121K (Employer provided)    3.7          \n",
      "8         Greenville, SC    $60K - $80K (Employer provided)    3.9          \n",
      "9   Westlake Village, CA   $80K - $130K (Employer provided)    4.0          \n",
      "10         Beaverton, OR     $101K - $147K (Glassdoor est.)    3.4          \n",
      "11                Remote   $87K - $132K (Employer provided)    4.3          \n",
      "12         Palo Alto, CA  $101K - $175K (Employer provided)    3.4          \n",
      "13          Syracuse, NY    $65K - $85K (Employer provided)    2.2          \n",
      "14           Boulder, CO                                N/A      0          \n",
      "15            Skokie, IL      $97K - $122K (Glassdoor est.)    3.1          \n",
      "16                Remote                                N/A    3.1          \n",
      "17     Overland Park, KS      $95K - $127K (Glassdoor est.)    3.6          \n",
      "18              Nash, TX      $71K - $111K (Glassdoor est.)    3.8          \n",
      "19     Beverly Hills, CA                                N/A    2.5          \n",
      "\n",
      "   Description  \n",
      "0               \n",
      "1               \n",
      "2               \n",
      "3               \n",
      "4               \n",
      "5               \n",
      "6               \n",
      "7               \n",
      "8               \n",
      "9               \n",
      "10              \n",
      "11              \n",
      "12              \n",
      "13              \n",
      "14              \n",
      "15              \n",
      "16              \n",
      "17              \n",
      "18              \n",
      "19              \n"
     ]
    }
   ],
   "source": [
    "import time, random\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "\n",
    "def get_jobs(keyword, num_jobs=40, verbose=False):\n",
    "    \"\"\"Scrape job listings from Glassdoor by attaching to an already open Chrome session.\"\"\"\n",
    "\n",
    "    # Attach to an already running Chrome session (start Chrome with --remote-debugging-port=9222)\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"debuggerAddress\", \"127.0.0.1:9222\")\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    # Open Glassdoor job search page\n",
    "    encoded_keyword = urllib.parse.quote_plus(keyword)\n",
    "    url = f\"https://www.glassdoor.com/Job/jobs.htm?sc.keyword={encoded_keyword}\"\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    jobs = []\n",
    "    page_num = 1\n",
    "\n",
    "    while len(jobs) < num_jobs:\n",
    "        print(\"Attempting to fetch new joblisting\")\n",
    "        try:\n",
    "            # Wait for job cards to load\n",
    "            job_cards = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.jobCard\"))\n",
    "            )\n",
    "\n",
    "            if verbose:\n",
    "                print(f\" Found {len(job_cards)} job cards on page {page_num}.\")\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\" Timeout: No jobs loaded or page blocked.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\" Error loading jobs: {e}\")\n",
    "            break\n",
    "\n",
    "        # Loop through job cards and extract information\n",
    "        for i, card in enumerate(job_cards):\n",
    "            if len(jobs) >= num_jobs:\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                # Extract job information using more specific selectors\n",
    "                job = extract_job_data(card)\n",
    "\n",
    "                # Only add job if we got at least the title or company\n",
    "                if job[\"title\"] or job[\"company\"]:\n",
    "                    jobs.append(job)\n",
    "\n",
    "                    if verbose:\n",
    "                        print(f\" Scraped {len(jobs)}/{num_jobs}: {job['title']} @ {job['company']}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\" Error scraping card {i + 1}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Check if we have enough jobs\n",
    "        if len(jobs) >= num_jobs:\n",
    "            break\n",
    "\n",
    "        # Go to next page\n",
    "        try:\n",
    "            # Try multiple selectors for next button\n",
    "            next_selectors = [\n",
    "                \"button[aria-label='Next Page']\",\n",
    "                \"button[aria-label='next']\",\n",
    "                \"a[aria-label='Next Page']\",\n",
    "                \"[data-test='pagination-next']\"\n",
    "            ]\n",
    "\n",
    "            next_btn = None\n",
    "            for selector in next_selectors:\n",
    "                try:\n",
    "                    next_btn = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                    if next_btn and next_btn.is_enabled():\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            if next_btn and next_btn.is_enabled():\n",
    "                driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "                page_num += 1\n",
    "                time.sleep(random.uniform(3, 5))\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\" No more pages available.\")\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\" No more pages or error navigating: {e}\")\n",
    "            break\n",
    "\n",
    "    # Create DataFrame with all columns\n",
    "    df = pd.DataFrame(jobs)\n",
    "\n",
    "    # Ensure all expected columns exist\n",
    "    expected_columns = [\"title\", \"company\", \"location\", \"salary\", \"rating\", \"Posted\", \"Description\"]\n",
    "    for col in expected_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "\n",
    "    # Reorder columns\n",
    "    df = df[expected_columns]\n",
    "\n",
    "    print(f\"\\n Total jobs scraped: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "def extract_job_data(job_card_element: WebElement) -> dict:\n",
    "    \"\"\"Extracts job details from a single job card WebElement.\"\"\"\n",
    "    job_data = {\n",
    "        \"title\": None,\n",
    "        \"company\": None,\n",
    "        \"location\": None,\n",
    "        \"salary\": None\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Job Title\n",
    "        title_element = job_card_element.find_element(By.CSS_SELECTOR, 'a[data-test=\"job-title\"]')\n",
    "        job_data[\"title\"] = title_element.text\n",
    "    except NoSuchElementException:\n",
    "        print(\"Job title not found.\")\n",
    "\n",
    "    try:\n",
    "        # Company\n",
    "        company_element = job_card_element.find_element(By.CSS_SELECTOR, 'span[class^=\"EmployerProfile_compactEmployerName__\"]')\n",
    "        job_data[\"company\"] = company_element.text\n",
    "    except NoSuchElementException:\n",
    "        print(\"Company not found.\")\n",
    "\n",
    "    try:\n",
    "        # Location\n",
    "        location_element = job_card_element.find_element(By.CSS_SELECTOR, '*[data-test=\"emp-location\"]')\n",
    "        job_data[\"location\"] = location_element.text\n",
    "    except NoSuchElementException:\n",
    "        print(\"Location not found.\")\n",
    "\n",
    "    try:\n",
    "        # Salary (handle cases where it's not present)\n",
    "        salary_element = job_card_element.find_element(By.CSS_SELECTOR, '*[data-test=\"detailSalary\"]')\n",
    "        job_data[\"salary\"] = salary_element.text\n",
    "    except NoSuchElementException:\n",
    "        job_data[\"salary\"] = \"N/A\" # Set to 'N/A' if salary is not available\n",
    "\n",
    "    try:\n",
    "        # Rating (handle cases where it's not present)\n",
    "        rating_element = job_card_element.find_element(By.CSS_SELECTOR, 'span[class^=\"rating-single-star_RatingText__\"]')\n",
    "        job_data[\"rating\"] = rating_element.text\n",
    "    except NoSuchElementException:\n",
    "        job_data[\"rating\"] = \"0\" # Set to 'N/A' if salary is not available\n",
    "\n",
    "    return job_data\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Make sure Chrome is running with: \n",
    "    # chrome.exe --remote-debugging-port=9222\n",
    "    print(\"Starting job scrapper\")\n",
    "    \n",
    "    df = get_jobs(\"software engineer\", num_jobs=20, verbose=True)\n",
    "    print(\"\\nFirst few jobs:\")\n",
    "    print(df)\n",
    "    \n",
    "    # Save to CSV\n",
    "    # df.to_csv(\"glassdoor_jobs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9cfb84-bfc0-429e-9e10-7c57df0bd994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter_env]",
   "language": "python",
   "name": "conda-env-jupyter_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
